{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "import statsmodels.api as sm\n",
    "from pandas.core import datetools\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train_val_test(train_path, val_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    val_data = pd.read_csv(val_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_name_dict = {}\n",
    "house_name_dict = {}\n",
    "name_dict = {}\n",
    "\n",
    "def enumerate_districts(df, type=None):\n",
    "    names = df['District']\n",
    "    count = 0\n",
    "    for name in names:\n",
    "        if type == 'senate':\n",
    "            if name not in senate_name_dict:\n",
    "                senate_name_dict[name] = count\n",
    "                count += 1\n",
    "        elif type == 'house':\n",
    "            if name not in house_name_dict:\n",
    "                house_name_dict[name] = count\n",
    "                count += 1\n",
    "        else:\n",
    "            if name not in name_dict:\n",
    "                name_dict[name] = count\n",
    "                count += 1\n",
    "\n",
    "def replace_district(x, type=None):\n",
    "    if type == \"senate\":\n",
    "        return senate_name_dict[x]\n",
    "    elif type == \"house\":\n",
    "        return house_name_dict[x]\n",
    "    else:\n",
    "        return name_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(df, phase, type=None):\n",
    "    \n",
    "    # replace district with number \n",
    "    df['District'] = df[\"District\"].apply(lambda x: replace_district(x, type))\n",
    "    \n",
    "    # code gender and party\n",
    "    df = df.drop(\"name\", axis=1)\n",
    "    df['sex'].replace('f', 1, inplace=True)\n",
    "    df['sex'].replace('m', 0, inplace=True)\n",
    "    df['party'].replace('Democratic', 1, inplace=True)\n",
    "    df['party'].replace('Republican', 0, inplace=True)\n",
    "\n",
    "    # fill NaN's with mean from column\n",
    "    df['sex'] = df['sex'].fillna(df['sex'].mean())\n",
    "    df['party'] = df['party'].fillna(df['party'].mean())\n",
    "    df['Amount'] = df['Amount'].fillna(df['Amount'].mean())   \n",
    "    df['vote_count'] = df['vote_count'].apply(lambda x: str(x).replace(\",\", \"\").replace('nan', 'NaN')).astype(float)\n",
    "    df['vote_count'] = df['vote_count'].fillna(df['vote_count'].mean())\n",
    "    df['vote_percent'] = df['vote_percent'].fillna(df['vote_percent'].mean())\n",
    "        \n",
    "    # add indicator for female democrat\n",
    "    df['female_dem'] = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row.sex == 1 and row.party == 1:\n",
    "            df.set_value(index, 'female_dem', 1)\n",
    "    \n",
    "    # remove \"(percent) margin of error\" columns\n",
    "    df = df.iloc[:, [index for index, x in enumerate(df.columns) if 'Margin' not in x]]\n",
    "    \n",
    "    # remove columns with low percent contributions\n",
    "    percent_cols = [col for index, col in enumerate(df.columns) if 'Percent' in col and df[col].mean() < 0.05]\n",
    "    for col in percent_cols:\n",
    "        df = df.drop(col, axis=1)\n",
    "        df = df.drop(col.replace(\"Percent\", \"Estimate\"), axis=1)\n",
    "        \n",
    "    if type == None:\n",
    "        df.to_csv('cleaned_data/cleaned_data_merged_' + phase + '.csv', index = False)\n",
    "    \n",
    "    else:\n",
    "        df.to_csv('cleaned_data/cleaned_data_' + str(type) + '_' + phase + '.csv', index=False)\n",
    "                  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_train_data, senate_val_data, senate_test_data = read_train_val_test(\"train_data/merged_senate_districts_2009_2012.csv\", \"valid_data/merged_senate_districts_2013_2014.csv\", \"test_data/merged_senate_districts_2015_2016.csv\")\n",
    "enumerate_districts(senate_train_data, 'senate')\n",
    "enumerate_districts(senate_val_data, 'senate')\n",
    "enumerate_districts(senate_test_data, 'senate')\n",
    "\n",
    "house_train_data, house_val_data, house_test_data = read_train_val_test(\"train_data/merged_house_districts_2009_2012.csv\", \"valid_data/merged_house_districts_2013_2014.csv\", \"test_data/merged_house_districts_2015_2016.csv\")\n",
    "enumerate_districts(house_train_data, 'house')\n",
    "enumerate_districts(house_val_data, 'house')\n",
    "enumerate_districts(house_test_data, 'house')\n",
    "\n",
    "merged_train = pd.concat([senate_train_data, house_train_data], axis=0)\n",
    "merged_val = pd.concat([senate_val_data, house_val_data], axis=0)\n",
    "merged_test = pd.concat([senate_test_data, house_test_data], axis=0)\n",
    "enumerate_districts(merged_train)\n",
    "enumerate_districts(merged_val)\n",
    "enumerate_districts(merged_test)\n",
    "\n",
    "cleaned_train_senate = clean_data(senate_train_data, 'train', 'senate')\n",
    "cleaned_val_senate = clean_data(senate_val_data, 'val', 'senate')\n",
    "cleaned_test_senate = clean_data(senate_test_data, 'test', 'senate')\n",
    "\n",
    "cleaned_train_house = clean_data(house_train_data, 'train', 'house')\n",
    "cleaned_val_house = clean_data(house_val_data, 'val', 'house')\n",
    "cleaned_test_house = clean_data(house_test_data, 'test', 'house')\n",
    "\n",
    "cleaned_train_merged = clean_data(merged_train, 'train')\n",
    "cleaned_val_merged = clean_data(merged_val, 'test')\n",
    "cleaned_test_merged = clean_data(merged_test, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_logistic_regression(train_df, val_df, indicator, test_df=None):\n",
    "    \n",
    "    if indicator == 'female':\n",
    "        y_train = train_df['sex']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['sex']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "    # scale data    \n",
    "    X_train = scale(X_train)\n",
    "    X_val = scale(X_val)\n",
    "    \n",
    "#     std_scaler = StandardScaler()\n",
    "#     X_train = std_scaler.fit_transform(X_train)\n",
    "#     X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "        \n",
    "    classifier = LR()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict_proba(X_val)\n",
    "    pred_round = [round(x) for x in pred]\n",
    "        \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_def['sex']\n",
    "            X_test = test_def.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "            \n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred_round = [round(x) for x in test_pred]\n",
    "\n",
    "        return test_pred_round, accuracy_score(y_test, test_pred_round)\n",
    "    \n",
    "    return pred, accuracy_score(y_val, pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_svm(train_df, val_df, test_df=None):\n",
    "\n",
    "    if indicator == 'female':\n",
    "    y_train = train_df['sex']\n",
    "    X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "    y_val = val_df['sex']\n",
    "    X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "    # scale data    \n",
    "    X_train = scale(X_train)\n",
    "    X_val = scale(X_val)\n",
    "    \n",
    "#     std_scaler = StandardScaler()\n",
    "#     X_train = std_scaler.fit_transform(X_train)\n",
    "#     X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "    \n",
    "    classifier = SVC()\n",
    "    classifier.fit(X_train, y_train)\n",
    "      \n",
    "    pred = classifier.predict_proba(X_val)\n",
    "    pred_round = [round(x) for x in pred]\n",
    "    \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_def['sex']\n",
    "            X_test = test_def.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred_round = [round(x) for x in test_pred]\n",
    "\n",
    "        return test_pred_round, accuracy_score(y_test, test_pred_round)\n",
    "    \n",
    "    return pred, accuracy_score(y_val, pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_knn(train_df, val_df, test_df=None):\n",
    "\n",
    "    if indicator == 'female':\n",
    "        y_train = train_df['sex']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['sex']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "    # scale data    \n",
    "    X_train = scale(X_train)\n",
    "    X_val = scale(X_val)\n",
    "    \n",
    "#     std_scaler = StandardScaler()\n",
    "#     X_train = std_scaler.fit_transform(X_train)\n",
    "#     X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "    \n",
    "    neigbors = list(range(1,16))\n",
    "    accuracy = []\n",
    "    preds = []\n",
    "        \n",
    "    for k in neighbors:\n",
    "        classifier = KNN(n_neighbors=k)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        preds.append(classifier.predict_proba(X_val))\n",
    "        accuracy.append(accuracy_score(y_val, pred))\n",
    "        \n",
    "    best_k, best_accuracy = max(accuracy)\n",
    "    pred = preds[best_k]\n",
    "    pred_round = [round(x) for x in pred]\n",
    "    \n",
    "    classifier = KNN(n_neighbors=best_k)\n",
    "    classifier.fit(X_train, y_train)\n",
    "        \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_def['sex']\n",
    "            X_test = test_def.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred_round = [round(x) for x in test_pred]\n",
    "        \n",
    "        return test_pred_round, accuracy_score(y_test, test_pred_round)\n",
    "\n",
    "    return pred, accuracy_score(y_val, pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_dtc(train_df, val_df, test_df=None):\n",
    "    \n",
    "    if indicator == 'female':\n",
    "        y_train = train_df['sex']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['sex']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "    # scale data    \n",
    "    X_train = scale(X_train)\n",
    "    X_val = scale(X_val)\n",
    "    \n",
    "#     std_scaler = StandardScaler()\n",
    "#     X_train = std_scaler.fit_transform(X_train)\n",
    "#     X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "    \n",
    "    classifier_gini = DTC(random_state=40)\n",
    "    classifier_entropy = DTC(criterion='entropy', random_state=40)\n",
    "    \n",
    "    classifier_gini.fit(X_train, y_train)\n",
    "    classifier_entropy.fit(X_train, y_train)\n",
    "    \n",
    "    pred_gini = classifier_gini.predict_proba(X_val)\n",
    "    pred_entropy = classifier_entropy.predict_proba(X_val)\n",
    "    \n",
    "    pred_round_gini = [round(x) for x in pred_gini]\n",
    "    pred_round_entropy = [round(x) for x in pred_entropy]\n",
    "    \n",
    "    accuracy_score_gini = accuracy_score(y_val, pred_round_gini)\n",
    "    accuracy_score_entropy = accuracy_score(y_val, pred_round_entropy)\n",
    "    \n",
    "    classifer = None\n",
    "    best_accuracy = None\n",
    "    best_preds = None\n",
    "    \n",
    "    if accuracy_score_gini > accuracy_score_entropy:\n",
    "        classifer = DTC(random_state=40)\n",
    "        best_accuracy = accuracy_score_gini\n",
    "        best_preds = pred_round_gini\n",
    "    \n",
    "    else:\n",
    "        classifier = DTC(criterion='entropy', random_state=40)\n",
    "        best_accuracy = accuracy_score_entropy\n",
    "        best_preds = pred_round_entropy        \n",
    "    \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_def['sex']\n",
    "            X_test = test_def.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred_round = [round(x) for x in test_pred]\n",
    "        \n",
    "        return test_pred_round, accuracy_score(y_test, test_pred_round)\n",
    "        \n",
    "    return best_preds, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def independent_columns(A, tol =0): #= 1e-05):\n",
    "    Q, R = np.linalg.qr(A)\n",
    "    independent = np.where(np.abs(R.diagonal()) > tol)[0]\n",
    "    \n",
    "    return independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_ols(train_df, val_df):\n",
    "    y_train = train_df['sex']\n",
    "    X_train = train_df.drop('sex', axis=1)\n",
    "    \n",
    "    y_val = val_df['sex']\n",
    "    X_val = val_df.drop('sex', axis=1)\n",
    "    \n",
    "    independent = independent_columns(X_train)\n",
    "    X_train = X_train.iloc[:, independent]\n",
    "    X_val = X_val.iloc[:, independent]\n",
    "    print(\"Rank is {}\".format(X_train.shape[1]))\n",
    "    X_train.to_csv(\"X_train.csv\")\n",
    "\n",
    "    classifier = sm.Logit(y_train, X_train)\n",
    "    results = classifier.fit(method='ncg')\n",
    "    pred = round(results.predict(X_val))\n",
    "    return accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_glm(train_df, val_df):\n",
    "    y_train = train_df['sex']\n",
    "    X_train = train_df.drop('sex', axis=1)\n",
    "    \n",
    "    y_val = val_df['sex']\n",
    "    X_val = val_df.drop('sex', axis=1)\n",
    "    \n",
    "    independent = independent_columns(X_train)\n",
    "    X_train = X_train.iloc[:, independent]\n",
    "    X_val = X_val.iloc[:, independent]\n",
    "    print(\"Rank is {}\".format(X_train.shape[1]))\n",
    "\n",
    "    classifier = sm.GLM(y_train, X_train)\n",
    "    results = classifier.fit()\n",
    "    #print(results.summary())\n",
    "    pred = round(results.predict(X_val))\n",
    "    return accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Berkshire, Hampshire & Franklin': 0, 'Bristol & Norfolk': 1, 'Cape & Islands': 2, 'First Bristol & Plymouth': 3, 'First Essex': 4, 'First Essex & Middlesex': 5, 'First Hampden & Hampshire': 6, 'First Middlesex': 7, 'First Middlesex & Norfolk': 8, 'First Plymouth & Bristol': 9, 'First Suffolk': 10, 'First Suffolk & Middlesex': 11, 'First Worcester': 12, 'Fourth Middlesex': 13, 'Hampden': 14, 'Hampshire & Franklin': 15, 'Middlesex & Essex': 16, 'Middlesex & Worcester': 17, 'Middlesex, Suffolk & Essex': 18, 'Norfolk & Plymouth': 19, 'Norfolk, Bristol & Middlesex': 20, 'Norfolk, Bristol & Plymouth': 21, 'Plymouth & Barnstable': 22, 'Plymouth & Norfolk': 23, 'Second Bristol & Plymouth': 24, 'Second Essex': 25, 'Second Essex & Middlesex': 26, 'Second Hampden & Hampshire': 27, 'Second Middlesex': 28, 'Second Middlesex & Norfolk': 29, 'Second Plymouth & Bristol': 30, 'Second Suffolk': 31, 'Second Suffolk & Middlesex': 32, 'Second Worcester': 33, 'Suffolk & Norfolk': 34, 'Third Essex & Middlesex': 35, 'Third Middlesex': 36, 'Worcester & Middlesex': 37, 'Worcester & Norfolk': 38, 'Worcester, Hampden, Hampshire & Franklin': 39, 'Berkshire, Hampshire, Franklin & Hampden': 40, 'Fifth Middlesex': 41, 'Hampshire, Franklin & Worcester': 42, 'Middlesex & Suffolk': 43, 'Norfolk & Suffolk': 44, 'Third Essex': 45, 'Worcester, Hampden, Hampshire & Middlesex': 46}\n",
      "(90, 163)\n",
      "(82, 163)\n",
      "(85, 163)\n",
      "Logistic Regression: \n",
      "0.719512195122\n",
      "SVM: \n",
      "0.743902439024\n",
      "K-Nearest Neighbors: \n",
      "-1.38374299064e-16\n",
      "0.817073170732\n",
      "Decision Tree Classifier: \n",
      "(0.76829268292682928, 0.68292682926829273)\n",
      "OLS Logistic Regression: \n",
      "Rank is 90\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.569945\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 1\n",
      "0.69512195122\n",
      "OLS Generalized Linear Model: \n",
      "Rank is 90\n",
      "0.463414634146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:473: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression: \")\n",
    "print(classify_logistic_regression(cleaned_train_senate, cleaned_val_senate))\n",
    "print(\"SVM: \")\n",
    "print(classify_svm(cleaned_train_senate, cleaned_val_senate))\n",
    "print(\"K-Nearest Neighbors: \")\n",
    "print(classify_knn(cleaned_train_senate, cleaned_val_senate))\n",
    "print(\"Decision Tree Classifier: \")\n",
    "print(classify_dtc(cleaned_train_senate, cleaned_val_senate))\n",
    "print(\"OLS Logistic Regression: \")\n",
    "print(classify_ols(cleaned_train_senate, cleaned_val_senate))\n",
    "print(\"OLS Generalized Linear Model: \")\n",
    "print(classify_glm(cleaned_train_senate, cleaned_val_senate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10th Bristol': 0, '10th Essex': 1, '10th Hampden': 2, '10th Middlesex': 3, '10th Norfolk': 4, '10th Plymouth': 5, '10th Suffolk': 6, '10th Worcester': 7, '11th Bristol': 8, '11th Essex': 9, '11th Hampden': 10, '11th Middlesex': 11, '11th Norfolk': 12, '11th Plymouth': 13, '11th Suffolk': 14, '11th Worcester': 15, '12th Bristol': 16, '12th Essex': 17, '12th Hampden': 18, '12th Middlesex': 19, '12th Norfolk': 20, '12th Plymouth': 21, '12th Suffolk': 22, '12th Worcester': 23, '13th Bristol': 24, '13th Essex': 25, '13th Middlesex': 26, '13th Norfolk': 27, '13th Suffolk': 28, '13th Worcester': 29, '14th Bristol': 30, '14th Essex': 31, '14th Middlesex': 32, '14th Norfolk': 33, '14th Suffolk': 34, '14th Worcester': 35, '15th Essex': 36, '15th Middlesex': 37, '15th Norfolk': 38, '15th Suffolk': 39, '15th Worcester': 40, '16th Essex': 41, '16th Middlesex': 42, '16th Suffolk': 43, '16th Worcester': 44, '17th Essex': 45, '17th Middlesex': 46, '17th Suffolk': 47, '17th Worcester': 48, '18th Essex': 49, '18th Middlesex': 50, '18th Suffolk': 51, '18th Worcester': 52, '19th Middlesex': 53, '19th Suffolk': 54, '1st Barnstable': 55, '1st Berkshire': 56, '1st Bristol': 57, '1st Essex': 58, '1st Franklin': 59, '1st Hampden': 60, '1st Hampshire': 61, '1st Middlesex': 62, '1st Norfolk': 63, '1st Plymouth': 64, '1st Suffolk': 65, '1st Worcester': 66, '20th Middlesex': 67, '21st Middlesex': 68, '22nd Middlesex': 69, '23rd Middlesex': 70, '24th Middlesex': 71, '25th Middlesex': 72, '26th Middlesex': 73, '27th Middlesex': 74, '28th Middlesex': 75, '29th Middlesex': 76, '2nd Barnstable': 77, '2nd Berkshire': 78, '2nd Bristol': 79, '2nd Essex': 80, '2nd Franklin': 81, '2nd Hampden': 82, '2nd Hampshire': 83, '2nd Middlesex': 84, '2nd Norfolk': 85, '2nd Plymouth': 86, '2nd Suffolk': 87, '2nd Worcester': 88, '30th Middlesex': 89, '31st Middlesex': 90, '32nd Middlesex': 91, '33rd Middlesex': 92, '34th Middlesex': 93, '35th Middlesex': 94, '36th Middlesex': 95, '37th Middlesex': 96, '3rd Barnstable': 97, '3rd Berkshire': 98, '3rd Bristol': 99, '3rd Essex': 100, '3rd Hampden': 101, '3rd Hampshire': 102, '3rd Middlesex': 103, '3rd Norfolk': 104, '3rd Plymouth': 105, '3rd Suffolk': 106, '3rd Worcester': 107, '4th Barnstable': 108, '4th Berkshire': 109, '4th Bristol': 110, '4th Essex': 111, '4th Hampden': 112, '4th Middlesex': 113, '4th Norfolk': 114, '4th Plymouth': 115, '4th Suffolk': 116, '4th Worcester': 117, '5th Barnstable': 118, '5th Bristol': 119, '5th Essex': 120, '5th Hampden': 121, '5th Middlesex': 122, '5th Norfolk': 123, '5th Plymouth': 124, '5th Suffolk': 125, '5th Worcester': 126, '6th Bristol': 127, '6th Essex': 128, '6th Hampden': 129, '6th Middlesex': 130, '6th Norfolk': 131, '6th Plymouth': 132, '6th Suffolk': 133, '6th Worcester': 134, '7th Bristol': 135, '7th Essex': 136, '7th Hampden': 137, '7th Middlesex': 138, '7th Norfolk': 139, '7th Plymouth': 140, '7th Suffolk': 141, '7th Worcester': 142, '8th Bristol': 143, '8th Essex': 144, '8th Hampden': 145, '8th Middlesex': 146, '8th Norfolk': 147, '8th Plymouth': 148, '8th Suffolk': 149, '8th Worcester': 150, '9th Bristol': 151, '9th Essex': 152, '9th Hampden': 153, '9th Middlesex': 154, '9th Norfolk': 155, '9th Plymouth': 156, '9th Suffolk': 157, '9th Worcester': 158, 'Barnstable, Dukes & Nantucket': 159}\n",
      "(325, 163)\n",
      "(172, 163)\n",
      "(166, 163)\n",
      "Logistic Regression: \n",
      "0.78488372093\n",
      "SVM: \n",
      "0.78488372093\n",
      "K-Nearest Neighbors: \n",
      "-8.90708842548e-18\n",
      "0.912790697674\n",
      "Decision Tree Classifier: \n",
      "(0.73837209302325579, 0.7558139534883721)\n",
      "OLS Logistic Regression: \n",
      "Rank is 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.517797\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 1\n",
      "0.767441860465\n",
      "OLS Generalized Linear Model: \n",
      "Rank is 162\n",
      "0.703488372093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:473: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    }
   ],
   "source": [
    "house_train_data, house_val_data, house_test_data = read_train_val_test(\"train_data/merged_house_districts_2009_2012.csv\", \"valid_data/merged_house_districts_2013_2014.csv\", \"test_data/merged_house_districts_2015_2016.csv\")\n",
    "enumerate_districts(house_train_data, \"house\")\n",
    "enumerate_districts(house_val_data, \"house\")\n",
    "enumerate_districts(house_test_data, \"house\")\n",
    "print(house_name_dict)\n",
    "    \n",
    "cleaned_train_house = clean_data(house_train_data,\"house\")\n",
    "cleaned_val_house = clean_data(house_val_data,\"house\")\n",
    "cleaned_test_house = clean_data(house_test_data,\"house\")\n",
    "\n",
    "print(\"Logistic Regression: \")\n",
    "print(classify_logistic_regression(cleaned_train_house, cleaned_val_house))\n",
    "print(\"SVM: \")\n",
    "print(classify_svm(cleaned_train_house, cleaned_val_house))\n",
    "print(\"K-Nearest Neighbors: \")\n",
    "print(classify_knn(cleaned_train_house, cleaned_val_house))\n",
    "print(\"Decision Tree Classifier: \")\n",
    "print(classify_dtc(cleaned_train_house, cleaned_val_house))\n",
    "print(\"OLS Logistic Regression: \")\n",
    "print(classify_ols(cleaned_train_house, cleaned_val_house))\n",
    "print(\"OLS Generalized Linear Model: \")\n",
    "print(classify_glm(cleaned_train_house, cleaned_val_house))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 163)\n",
      "(254, 163)\n",
      "(166, 163)\n",
      "Logistic Regression: \n",
      "0.759842519685\n",
      "SVM: \n",
      "0.763779527559\n",
      "K-Nearest Neighbors: \n",
      "-8.31238824446e-17\n",
      "0.913385826772\n",
      "Decision Tree Classifier: \n",
      "(0.74409448818897639, 0.75196850393700787)\n",
      "OLS Logistic Regression: \n",
      "Rank is 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.594055\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 1\n",
      "0.744094488189\n",
      "OLS Generalized Linear Model: \n",
      "Rank is 162\n",
      "0.657480314961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:473: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    }
   ],
   "source": [
    "merged_train = pd.concat([senate_train_data, house_train_data], axis=0)\n",
    "merged_val = pd.concat([senate_val_data, house_val_data], axis=0)\n",
    "merged_test = pd.concat([senate_test_data, house_test_data], axis=0)\n",
    "\n",
    "enumerate_districts(merged_train)\n",
    "enumerate_districts(merged_val)\n",
    "enumerate_districts(merged_test)\n",
    "    \n",
    "cleaned_train = clean_data(merged_train)\n",
    "cleaned_val = clean_data(merged_val)\n",
    "cleaned_test = clean_data(house_test_data)\n",
    "\n",
    "print(\"Logistic Regression: \")\n",
    "print(classify_logistic_regression(cleaned_train, cleaned_val))\n",
    "print(\"SVM: \")\n",
    "print(classify_svm(cleaned_train, cleaned_val))\n",
    "print(\"K-Nearest Neighbors: \")\n",
    "print(classify_knn(cleaned_train, cleaned_val))\n",
    "print(\"Decision Tree Classifier: \")\n",
    "print(classify_dtc(cleaned_train, cleaned_val))\n",
    "print(\"OLS Logistic Regression: \")\n",
    "print(classify_ols(cleaned_train, cleaned_val))\n",
    "print(\"OLS Generalized Linear Model: \")\n",
    "print(classify_glm(cleaned_train, cleaned_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(enumerate_districts(house_test_data))\n",
    "      \n",
    "# enumerate_districts(merged_train)\n",
    "# enumerate_districts(merged_val)\n",
    "# enumerate_districts(merged_test)\n",
    "    \n",
    "# cleaned_train = clean_data(merged_train)\n",
    "# cleaned_val = clean_data(merged_val)\n",
    "# cleaned_test = clean_data(house_test_data)\n",
    "\n",
    "# print(\"Logistic Regression: \")\n",
    "# print(classify_logistic_regression(cleaned_train, cleaned_val))\n",
    "# print(\"SVM: \")\n",
    "# print(classify_svm(cleaned_train, cleaned_val))\n",
    "# print(\"K-Nearest Neighbors: \")\n",
    "# print(classify_knn(cleaned_train, cleaned_val))\n",
    "# print(\"Decision Tree Classifier: \")\n",
    "# print(classify_dtc(cleaned_train, cleaned_val))\n",
    "# print(\"OLS Logistic Regression: \")\n",
    "# print(classify_ols(cleaned_train, cleaned_val))\n",
    "# print(\"OLS Generalized Linear Model: \")\n",
    "# print(classify_glm(cleaned_train, cleaned_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Senate Decision Tree Classifier: \n",
      "Test accuracy: 0.7647058823529411\n",
      "(0.76829268292682928, 0.68292682926829273)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test senate Decision Tree Classifier: \")\n",
    "print(classify_dtc(cleaned_train_senate, cleaned_val_senate, cleaned_test_senate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test House KNN Classifier: \n",
      "-8.90708842548e-18\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors > 0. Got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-0a9aac7565d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test House KNN Classifier: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassify_knn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_train_house\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleaned_val_house\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleaned_test_house\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-118-0199793fcc8d>\u001b[0m in \u001b[0;36mclassify_knn\u001b[1;34m(train_df, val_df, test_df)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 raise ValueError(\n\u001b[0;32m    254\u001b[0m                     \u001b[1;34m\"Expected n_neighbors > 0. Got %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                 )\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors > 0. Got 0"
     ]
    }
   ],
   "source": [
    "print(\"Test house KNN Classifier: \")\n",
    "print(classify_knn(cleaned_train_house, cleaned_val_house, cleaned_test_house))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
