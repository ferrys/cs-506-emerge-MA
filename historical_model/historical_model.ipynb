{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "import statsmodels.api as sm\n",
    "from pandas.core import datetools\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train_val_test(train_path, val_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    val_data = pd.read_csv(val_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_name_dict = {}\n",
    "house_name_dict = {}\n",
    "name_dict = {}\n",
    "\n",
    "def enumerate_districts(df, type=None):\n",
    "    names = df['District']\n",
    "    count = 0\n",
    "    for name in names:\n",
    "        if type == 'senate':\n",
    "            if name not in senate_name_dict:\n",
    "                senate_name_dict[name] = count\n",
    "                count += 1\n",
    "        elif type == 'house':\n",
    "            if name not in house_name_dict:\n",
    "                house_name_dict[name] = count\n",
    "                count += 1\n",
    "        else:\n",
    "            if name not in name_dict:\n",
    "                name_dict[name] = count\n",
    "                count += 1\n",
    "\n",
    "def replace_district(x, type=None):\n",
    "    if type == \"senate\":\n",
    "        return senate_name_dict[x]\n",
    "    elif type == \"house\":\n",
    "        return house_name_dict[x]\n",
    "    else:\n",
    "        return name_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, phase, type=None):\n",
    "    \n",
    "    # replace district with number \n",
    "    df['District'] = df[\"District\"].apply(lambda x: replace_district(x, type))\n",
    "    \n",
    "    # code gender and party\n",
    "    df = df.drop(\"name\", axis=1)\n",
    "    df['sex'].replace('f', 1, inplace=True)\n",
    "    df['sex'].replace('m', 0, inplace=True)\n",
    "    df['party'].replace('Democratic', 1, inplace=True)\n",
    "    df['party'].replace('Republican', 0, inplace=True)\n",
    "\n",
    "    # fill NaN's with mean from column\n",
    "    df['sex'] = df['sex'].fillna(round((df['sex'].mean())))\n",
    "    df['party'] = df['party'].fillna(df['party'].mean())\n",
    "    df['Amount'] = df['Amount'].fillna(df['Amount'].mean())   \n",
    "    df['vote_count'] = df['vote_count'].apply(lambda x: str(x).replace(\",\", \"\").replace('nan', 'NaN')).astype(float)\n",
    "    df['vote_count'] = df['vote_count'].fillna(df['vote_count'].mean())\n",
    "    df['vote_percent'] = df['vote_percent'].fillna(df['vote_percent'].mean())\n",
    "        \n",
    "    # add indicator for female democrat\n",
    "    df['female_dem'] = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row.sex == 1 and row.party == 1:\n",
    "            df.set_value(index, 'female_dem', 1)\n",
    "    \n",
    "    # remove \"(percent) margin of error\" columns\n",
    "    df = df.iloc[:, [index for index, x in enumerate(df.columns) if 'Margin' not in x]]\n",
    "    \n",
    "    # remove columns with low percent contributions\n",
    "    percent_cols = [col for index, col in enumerate(df.columns) if 'Percent' in col and df[col].mean() < 0.05]\n",
    "    for col in percent_cols:\n",
    "        df = df.drop(col, axis=1)\n",
    "        df = df.drop(col.replace(\"Percent\", \"Estimate\"), axis=1)\n",
    "        \n",
    "    if type == None:\n",
    "        df.to_csv('cleaned_data/cleaned_data_merged_' + phase + '.csv', index = False)\n",
    "    \n",
    "    else:\n",
    "        df.to_csv('cleaned_data/cleaned_data_' + str(type) + '_' + phase + '.csv', index=False)\n",
    "                  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_train_data, senate_val_data, senate_test_data = read_train_val_test(\"train_data/merged_senate_districts_2009_2012.csv\", \"valid_data/merged_senate_districts_2013_2014.csv\", \"test_data/merged_senate_districts_2015_2016.csv\")\n",
    "enumerate_districts(senate_train_data, 'senate')\n",
    "enumerate_districts(senate_val_data, 'senate')\n",
    "enumerate_districts(senate_test_data, 'senate')\n",
    "\n",
    "house_train_data, house_val_data, house_test_data = read_train_val_test(\"train_data/merged_house_districts_2009_2012.csv\", \"valid_data/merged_house_districts_2013_2014.csv\", \"test_data/merged_house_districts_2015_2016.csv\")\n",
    "enumerate_districts(house_train_data, 'house')\n",
    "enumerate_districts(house_val_data, 'house')\n",
    "enumerate_districts(house_test_data, 'house')\n",
    "\n",
    "merged_train = pd.concat([senate_train_data, house_train_data], axis=0)\n",
    "merged_val = pd.concat([senate_val_data, house_val_data], axis=0)\n",
    "merged_test = pd.concat([senate_test_data, house_test_data], axis=0)\n",
    "enumerate_districts(merged_train)\n",
    "enumerate_districts(merged_val)\n",
    "enumerate_districts(merged_test)\n",
    "\n",
    "cleaned_train_senate = clean_data(senate_train_data, 'train', 'senate')\n",
    "cleaned_val_senate = clean_data(senate_val_data, 'val', 'senate')\n",
    "cleaned_test_senate = clean_data(senate_test_data, 'test', 'senate')\n",
    "\n",
    "cleaned_train_house = clean_data(house_train_data, 'train', 'house')\n",
    "cleaned_val_house = clean_data(house_val_data, 'val', 'house')\n",
    "cleaned_test_house = clean_data(house_test_data, 'test', 'house')\n",
    "\n",
    "cleaned_train_merged = clean_data(merged_train, 'train')\n",
    "cleaned_val_merged = clean_data(merged_val, 'test')\n",
    "cleaned_test_merged = clean_data(merged_test, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_lr(train_df, val_df, indicator, test_df=None):\n",
    "    \n",
    "    if indicator == 'female':\n",
    "        y_train = train_df['sex']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['sex']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "#   scale data    \n",
    "#     X_train = scale(X_train)\n",
    "#     X_val = scale(X_val)\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train = std_scaler.fit_transform(X_train)\n",
    "    X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "        \n",
    "    classifier = LR()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict_proba(X_val)\n",
    "    pred = np.delete(pred, 1, 1)    \n",
    "    pred_round =  classifier.predict(X_val)\n",
    "                \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_df['sex']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred = np.delete(test_pred, 1, 1)    \n",
    "        test_pred_round = classifier.predict(X_test)\n",
    "        \n",
    "        print(test_pred)\n",
    "        \n",
    "        return test_pred, accuracy_score(y_test, test_pred_round)\n",
    "    \n",
    "    return pred, accuracy_score(y_val, pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_svm(train_df, val_df, indicator, test_df=None):\n",
    "\n",
    "    if indicator == 'female':\n",
    "        y_train = train_df['sex']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['sex']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "#   scale data    \n",
    "#     X_train = scale(X_train)\n",
    "#     X_val = scale(X_val)\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train = std_scaler.fit_transform(X_train)\n",
    "    X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "    \n",
    "    classifier = SVC(probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "      \n",
    "    pred = classifier.predict_proba(X_val)\n",
    "    pred = np.delete(pred, 1, 1)    \n",
    "    pred_round = classifier.predict(X_val)\n",
    "    \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_df['sex']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred = np.delete(test_pred, 1, 1)    \n",
    "        test_pred_round = classifier.predict(X_test)\n",
    "\n",
    "        return test_pred, accuracy_score(y_test, test_pred_round)\n",
    "    \n",
    "    return pred, accuracy_score(y_val, pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def classify_knn(train_df, val_df, indicator, test_df=None):\n",
    "\n",
    "    if indicator == 'female':\n",
    "        y_train = train_df['sex']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['sex']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "#   scale data    \n",
    "#     X_train = scale(X_train)\n",
    "#     X_val = scale(X_val)\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train = std_scaler.fit_transform(X_train)\n",
    "    X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "    \n",
    "    neighbors = list(range(1,16))\n",
    "    accuracy = []\n",
    "    preds = np.zeros((y_val.shape[0],1))\n",
    "    preds_round = np.zeros((y_val.shape[0],1))\n",
    "        \n",
    "    for k in neighbors:\n",
    "        classifier = KNN(n_neighbors=k)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        k_pred = classifier.predict_proba(X_val)\n",
    "        k_pred = np.delete(k_pred, 1, 1) \n",
    "        preds = np.concatenate((preds, k_pred), axis=1)\n",
    "        k_pred_round = (classifier.predict(X_val)).reshape((y_val.shape[0],1))\n",
    "        preds_round = np.concatenate((preds_round, k_pred_round), axis=1)\n",
    "        accuracy.append(accuracy_score(y_val, k_pred_round))\n",
    "        \n",
    "    preds = np.delete(preds, 0, 1)\n",
    "    preds_round = np.delete(preds_round, 0, 1)\n",
    "    \n",
    "    best_k = None\n",
    "    best_accuracy = -math.inf\n",
    "    \n",
    "    for k, acc in enumerate(accuracy):\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_k = k + 1  \n",
    "    \n",
    "    pred = preds[:,best_k]\n",
    "    pred_round = preds_round[:,best_k]\n",
    "    classifier = KNN(n_neighbors=best_k)\n",
    "    classifier.fit(X_train, y_train)\n",
    "        \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_df['sex']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred = np.delete(test_pred, 1, 1)    \n",
    "        test_pred_round = classifier.predict(X_test)\n",
    "        \n",
    "        return test_pred, accuracy_score(y_test, test_pred_round), best_k\n",
    "\n",
    "    return pred, accuracy_score(y_val, pred_round), best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_dtc(train_df, val_df, indicator, test_df=None):\n",
    "    \n",
    "    if indicator == 'female':\n",
    "        y_train = train_df['sex']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['sex']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "    elif indicator == 'female_dem':\n",
    "        y_train = train_df['female_dem']\n",
    "        X_train = train_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        y_val = val_df['female_dem']\n",
    "        X_val = val_df.drop(['sex', 'female_dem'], axis=1)\n",
    "        \n",
    "#   scale data    \n",
    "#     X_train = scale(X_train)\n",
    "#     X_val = scale(X_val)\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    X_train = std_scaler.fit_transform(X_train)\n",
    "    X_val = std_scaler.fit_transform(X_val)\n",
    "    \n",
    "#     mm_scaler = MinMaxScaler()\n",
    "#     X_train = mm_scaler.fit_transform(X_train)\n",
    "#     X_val = mm_scaler.fit_transform(X_val)\n",
    "    \n",
    "    classifier_gini = DTC(random_state=40)\n",
    "    classifier_entropy = DTC(criterion='entropy', random_state=40)\n",
    "    \n",
    "    classifier_gini.fit(X_train, y_train)\n",
    "    classifier_entropy.fit(X_train, y_train)\n",
    "    \n",
    "    pred_gini = classifier_gini.predict_proba(X_val)\n",
    "    pred_gini = np.delete(pred_gini, 1, 1)    \n",
    "    pred_entropy = classifier_entropy.predict_proba(X_val)\n",
    "    pred_entropy = np.delete(pred_entropy, 1, 1)    \n",
    "    pred_round_gini = classifier_gini.predict(X_val)\n",
    "    pred_round_entropy = classifier_entropy.predict(X_val)\n",
    "    \n",
    "    accuracy_score_gini = accuracy_score(y_val, pred_round_gini)\n",
    "    accuracy_score_entropy = accuracy_score(y_val, pred_round_entropy)\n",
    "    \n",
    "    classifer = None\n",
    "    best_accuracy = None\n",
    "    best_preds = None\n",
    "    \n",
    "    if accuracy_score_gini > accuracy_score_entropy:\n",
    "        classifier = DTC(random_state=40)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        best_accuracy = accuracy_score_gini\n",
    "        best_preds = pred_round_gini\n",
    "    \n",
    "    else:\n",
    "        classifier = DTC(criterion='entropy', random_state=40)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        best_accuracy = accuracy_score_entropy\n",
    "        best_preds = pred_round_entropy        \n",
    "    \n",
    "    if test_df is not None:\n",
    "        \n",
    "        if indicator == 'female':\n",
    "            y_test = test_df['sex']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "    \n",
    "        elif indicator == 'female_dem':\n",
    "            y_test = test_df['female_dem']\n",
    "            X_test = test_df.drop(['sex', 'female_dem'], axis=1)\n",
    "\n",
    "        test_pred = classifier.predict_proba(X_test)\n",
    "        test_pred = np.delete(test_pred, 1, 1)    \n",
    "        test_pred_round = classifier.predict(X_test)\n",
    "        \n",
    "        return test_pred, accuracy_score(y_test, test_pred_round)\n",
    "        \n",
    "    return best_preds, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# senate data val results, indicator = 'female'\n",
    "senate_val_lr_female_preds = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female')[0]\n",
    "senate_val_lr_female_accuracy = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female')[1]\n",
    "\n",
    "senate_val_svm_female_preds = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female')[0]\n",
    "senate_val_svm_female_accuracy = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female')[1]\n",
    "\n",
    "senate_val_knn_female_preds = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female')[0]\n",
    "senate_val_knn_female_accuracy = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female')[1]\n",
    "senate_val_knn_female_bestk = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female')[2]\n",
    "\n",
    "senate_val_dtc_female_preds = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female')[0]\n",
    "senate_val_dtc_female_accuracy = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female')[1]\n",
    "\n",
    "\n",
    "# senate data val results, indicator = 'female_dem'\n",
    "senate_val_lr_femaleDem_preds = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female_dem')[0]\n",
    "senate_val_lr_femaleDem_accuracy = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female_dem')[1]\n",
    "\n",
    "senate_val_svm_femaleDem_preds = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female_dem')[0]\n",
    "senate_val_svm_femaleDem_accuracy = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female_dem')[1]\n",
    "\n",
    "senate_val_knn_femaleDem_preds = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female_dem')[0]\n",
    "senate_val_knn_femaleDem_accuracy = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female_dem')[1]\n",
    "senate_val_knn_femaleDem_bestk = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female_dem')[2]\n",
    "\n",
    "senate_val_dtc_femaleDem_preds = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female_dem')[0]\n",
    "senate_val_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female_dem')[1]\n",
    "\n",
    "# senate data test results, indicator = 'female'\n",
    "senate_test_lr_female_preds = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[0]\n",
    "senate_test_lr_female_accuracy = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[1]\n",
    "\n",
    "senate_test_svm_female_preds = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[0]\n",
    "senate_test_svm_female_accuracy = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[1]\n",
    "\n",
    "senate_test_knn_female_preds = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[0]\n",
    "senate_test_knn_female_accuracy = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[1]\n",
    "senate_test_knn_female_bestk = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[2]\n",
    "\n",
    "senate_test_dtc_female_preds = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[0]\n",
    "senate_test_dtc_female_accuracy = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female', cleaned_test_senate)[1]\n",
    "\n",
    "\n",
    "# senate data test results, indicator = 'female_dem'\n",
    "senate_test_lr_femaleDem_preds = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[0]\n",
    "senate_test_lr_femaleDem_accuracy = classify_lr(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[1]\n",
    "\n",
    "senate_test_svm_femaleDem_preds = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[0]\n",
    "senate_test_svm_femaleDem_accuracy = classify_svm(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[1]\n",
    "\n",
    "senate_test_knn_femaleDem_preds = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[0]\n",
    "senate_test_knn_femaleDem_accuracy = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[1]\n",
    "senate_test_knn_femaleDem_bestk = classify_knn(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[2]\n",
    "\n",
    "senate_test_dtc_femaleDem_preds = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[0]\n",
    "senate_test_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_senate, cleaned_val_senate, 'female_dem', cleaned_test_senate)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# house data val results, indicator = 'female'\n",
    "house_val_lr_female_preds = classify_lr(cleaned_train_house, cleaned_val_house, 'female')[0]\n",
    "house_val_lr_female_accuracy = classify_lr(cleaned_train_house, cleaned_val_house, 'female')[1]\n",
    "\n",
    "house_val_svm_female_preds = classify_svm(cleaned_train_house, cleaned_val_house, 'female')[0]\n",
    "house_val_svm_female_accuracy = classify_svm(cleaned_train_house, cleaned_val_house, 'female')[1]\n",
    "\n",
    "house_val_knn_female_preds = classify_knn(cleaned_train_house, cleaned_val_house, 'female')[0]\n",
    "house_val_knn_female_accuracy = classify_knn(cleaned_train_house, cleaned_val_house, 'female')[1]\n",
    "house_val_knn_female_bestk = classify_knn(cleaned_train_house, cleaned_val_house, 'female')[2]\n",
    "\n",
    "house_val_dtc_female_preds = classify_dtc(cleaned_train_house, cleaned_val_house, 'female')[0]\n",
    "house_val_dtc_female_accuracy = classify_dtc(cleaned_train_house, cleaned_val_house, 'female')[1]\n",
    "\n",
    "\n",
    "# house data val results, indicator = 'female_dem'\n",
    "house_val_lr_femaleDem_preds = classify_lr(cleaned_train_house, cleaned_val_house, 'female_dem')[0]\n",
    "house_val_lr_femaleDem_accuracy = classify_lr(cleaned_train_house, cleaned_val_house, 'female_dem')[1]\n",
    "\n",
    "house_val_svm_femaleDem_preds = classify_svm(cleaned_train_house, cleaned_val_house, 'female_dem')[0]\n",
    "house_val_svm_femaleDem_accuracy = classify_svm(cleaned_train_house, cleaned_val_house, 'female_dem')[1]\n",
    "\n",
    "house_val_knn_femaleDem_preds = classify_knn(cleaned_train_house, cleaned_val_house, 'female_dem')[0]\n",
    "house_val_knn_femaleDem_accuracy = classify_knn(cleaned_train_house, cleaned_val_house, 'female_dem')[1]\n",
    "house_val_knn_femaleDem_bestk = classify_knn(cleaned_train_house, cleaned_val_house, 'female_dem')[2]\n",
    "\n",
    "house_val_dtc_femaleDem_preds = classify_dtc(cleaned_train_house, cleaned_val_house, 'female_dem')[0]\n",
    "house_val_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_house, cleaned_val_house, 'female_dem')[1]\n",
    "\n",
    "# house data test results, indicator = 'female'\n",
    "house_test_lr_female_preds = classify_lr(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[0]\n",
    "house_test_lr_female_accuracy = classify_lr(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[1]\n",
    "\n",
    "house_test_svm_female_preds = classify_svm(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[0]\n",
    "house_test_svm_female_accuracy = classify_svm(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[1]\n",
    "\n",
    "house_test_knn_female_preds = classify_knn(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[0]\n",
    "house_test_knn_female_accuracy = classify_knn(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[1]\n",
    "house_test_knn_female_bestk = classify_knn(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[2]\n",
    "\n",
    "house_test_dtc_female_preds = classify_dtc(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[0]\n",
    "house_test_dtc_female_accuracy = classify_dtc(cleaned_train_house, cleaned_val_house, 'female', cleaned_test_house)[1]\n",
    "\n",
    "\n",
    "# house data test results, indicator = 'female_dem'\n",
    "house_test_lr_femaleDem_preds = classify_lr(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[0]\n",
    "house_test_lr_femaleDem_accuracy = classify_lr(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[1]\n",
    "\n",
    "house_test_svm_femaleDem_preds = classify_svm(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[0]\n",
    "house_test_svm_femaleDem_accuracy = classify_svm(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[1]\n",
    "\n",
    "house_test_knn_femaleDem_preds = classify_knn(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[0]\n",
    "house_test_knn_femaleDem_accuracy = classify_knn(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[1]\n",
    "house_test_knn_femaleDem_bestk = classify_knn(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[2]\n",
    "\n",
    "house_test_dtc_femaleDem_preds = classify_dtc(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[0]\n",
    "house_test_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_house, cleaned_val_house, 'female_dem', cleaned_test_house)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# merged data val results, indicator = 'female'\n",
    "merged_val_lr_female_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female')[0]\n",
    "merged_val_lr_female_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female')[1]\n",
    "\n",
    "merged_val_svm_female_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female')[0]\n",
    "merged_val_svm_female_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female')[1]\n",
    "\n",
    "merged_val_knn_female_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female')[0]\n",
    "merged_val_knn_female_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female')[1]\n",
    "merged_val_knn_female_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female')[2]\n",
    "\n",
    "merged_val_dtc_female_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female')[0]\n",
    "merged_val_dtc_female_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female')[1]\n",
    "\n",
    "\n",
    "# merged data val results, indicator = 'female_dem'\n",
    "merged_val_lr_femaleDem_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem')[0]\n",
    "merged_val_lr_femaleDem_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem')[1]\n",
    "\n",
    "merged_val_svm_femaleDem_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem')[0]\n",
    "merged_val_svm_femaleDem_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem')[1]\n",
    "\n",
    "merged_val_knn_femaleDem_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem')[0]\n",
    "merged_val_knn_femaleDem_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem')[1]\n",
    "merged_val_knn_femaleDem_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem')[2]\n",
    "\n",
    "merged_val_dtc_femaleDem_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem')[0]\n",
    "merged_val_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem')[1]\n",
    "\n",
    "# merged data test results, indicator = 'female'\n",
    "merged_test_lr_female_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[0]\n",
    "merged_test_lr_female_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[1]\n",
    "\n",
    "merged_test_svm_female_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[0]\n",
    "merged_test_svm_female_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[1]\n",
    "\n",
    "merged_test_knn_female_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[0]\n",
    "merged_test_knn_female_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[1]\n",
    "merged_test_knn_female_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[2]\n",
    "\n",
    "merged_test_dtc_female_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[0]\n",
    "merged_test_dtc_female_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_merged)[1]\n",
    "\n",
    "\n",
    "# merged data test results, indicator = 'female_dem'\n",
    "merged_test_lr_femaleDem_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[0]\n",
    "merged_test_lr_femaleDem_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[1]\n",
    "\n",
    "merged_test_svm_femaleDem_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[0]\n",
    "merged_test_svm_femaleDem_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[1]\n",
    "\n",
    "merged_test_knn_femaleDem_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[0]\n",
    "merged_test_knn_femaleDem_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[1]\n",
    "merged_test_knn_femaleDem_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[2]\n",
    "\n",
    "merged_test_dtc_femaleDem_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[0]\n",
    "merged_test_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_merged)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "# merged data, test on senate results, indicator = 'female'\n",
    "merged_test_senate_lr_female_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[0]\n",
    "merged_test_senate_lr_female_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[1]\n",
    "\n",
    "merged_test_senate_svm_female_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[0]\n",
    "merged_test_senate_svm_female_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[1]\n",
    "\n",
    "merged_test_senate_knn_female_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[0]\n",
    "merged_test_senate_knn_female_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[1]\n",
    "merged_test_senate_knn_female_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[2]\n",
    "\n",
    "merged_test_senate_dtc_female_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[0]\n",
    "merged_test_senate_dtc_female_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_senate)[1]\n",
    "\n",
    "\n",
    "# merged data test on senate results, indicator = 'female_dem'\n",
    "merged_test_senate_lr_femaleDem_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[0]\n",
    "merged_test_senate_lr_femaleDem_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[1]\n",
    "\n",
    "merged_test_senate_svm_femaleDem_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[0]\n",
    "merged_test_senate_svm_femaleDem_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[1]\n",
    "\n",
    "merged_test_senate_knn_femaleDem_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[0]\n",
    "merged_test_senate_knn_femaleDem_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[1]\n",
    "merged_test_senate_knn_femaleDem_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[2]\n",
    "\n",
    "merged_test_senate_dtc_femaleDem_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[0]\n",
    "merged_test_senate_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_senate)[1]\n",
    "\n",
    "\n",
    "# merged data test on house results, indicator = 'female'\n",
    "merged_test_house_lr_female_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[0]\n",
    "merged_test_house_lr_female_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[1]\n",
    "\n",
    "merged_test_house_svm_female_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[0]\n",
    "merged_test_house_svm_female_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[1]\n",
    "\n",
    "merged_test_house_knn_female_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[0]\n",
    "merged_test_house_knn_female_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[1]\n",
    "merged_test_house_knn_female_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[2]\n",
    "\n",
    "merged_test_house_dtc_female_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[0]\n",
    "merged_test_house_dtc_female_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female', cleaned_test_house)[1]\n",
    "\n",
    "\n",
    "# merged data test on house results, indicator = 'female_dem'\n",
    "merged_test_house_lr_femaleDem_preds = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[0]\n",
    "merged_test_house_lr_femaleDem_accuracy = classify_lr(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[1]\n",
    "\n",
    "merged_test_house_svm_femaleDem_preds = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[0]\n",
    "merged_test_house_svm_femaleDem_accuracy = classify_svm(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[1]\n",
    "\n",
    "merged_test_house_knn_femaleDem_preds = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[0]\n",
    "merged_test_house_knn_femaleDem_accuracy = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[1]\n",
    "merged_test_house_knn_femaleDem_bestk = classify_knn(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[2]\n",
    "\n",
    "merged_test_house_dtc_femaleDem_preds = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[0]\n",
    "merged_test_house_dtc_femaleDem_accuracy = classify_dtc(cleaned_train_merged, cleaned_val_merged, 'female_dem', cleaned_test_house)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senate, val, indicator=female, LR: 0.719512195122\n",
      "Senate, val, indicator=female, SVM: 0.743902439024\n",
      "Senate, val, indicator=female, KNN: 0.817073170732\n",
      "Senate, val, indicator=female, DTC: 0.719512195122\n",
      "\n",
      "\n",
      "Senate, val, indicator=female_dem, LR: 0.719512195122\n",
      "Senate, val, indicator=female_dem, SVM: 0.743902439024\n",
      "Senate, val, indicator=female_dem, KNN: 0.817073170732\n",
      "Senate, val, indicator=female_dem, DTC: 0.719512195122\n",
      "\n",
      "\n",
      "Senate, test, indicator=female, LR: 0.705882352941\n",
      "Senate, test, indicator=female, SVM: 0.717647058824\n",
      "Senate, test, indicator=female, KNN: 0.305882352941\n",
      "Senate, test, indicator=female, DTC: 0.282352941176\n",
      "\n",
      "\n",
      "Senate, test, indicator=female_dem, LR: 0.705882352941\n",
      "Senate, test, indicator=female_dem, SVM: 0.717647058824\n",
      "Senate, test, indicator=female_dem, KNN: 0.305882352941\n",
      "Senate, test, indicator=female_dem, DTC: 0.282352941176\n"
     ]
    }
   ],
   "source": [
    "# Senate accuracies\n",
    "\n",
    "print('Senate, val, indicator=female, LR: ' + str(senate_val_lr_female_accuracy))\n",
    "print('Senate, val, indicator=female, SVM: ' + str(senate_val_svm_female_accuracy))\n",
    "print('Senate, val, indicator=female, KNN: ' + str(senate_val_knn_female_accuracy))\n",
    "print('Senate, val, indicator=female, DTC: ' + str(senate_val_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('Senate, val, indicator=female_dem, LR: ' + str(senate_val_lr_femaleDem_accuracy))\n",
    "print('Senate, val, indicator=female_dem, SVM: ' + str(senate_val_svm_femaleDem_accuracy))\n",
    "print('Senate, val, indicator=female_dem, KNN: ' + str(senate_val_knn_femaleDem_accuracy))\n",
    "print('Senate, val, indicator=female_dem, DTC: ' + str(senate_val_dtc_femaleDem_accuracy))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Senate, test, indicator=female, LR: ' + str(senate_test_lr_female_accuracy))\n",
    "print('Senate, test, indicator=female, SVM: ' + str(senate_test_svm_female_accuracy))\n",
    "print('Senate, test, indicator=female, KNN: ' + str(senate_test_knn_female_accuracy))\n",
    "print('Senate, test, indicator=female, DTC: ' + str(senate_test_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('Senate, test, indicator=female_dem, LR: ' + str(senate_test_lr_femaleDem_accuracy))\n",
    "print('Senate, test, indicator=female_dem, SVM: ' + str(senate_test_svm_femaleDem_accuracy))\n",
    "print('Senate, test, indicator=female_dem, KNN: ' + str(senate_test_knn_femaleDem_accuracy))\n",
    "print('Senate, test, indicator=female_dem, DTC: ' + str(senate_test_dtc_femaleDem_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House, val, indicator=female, LR: 0.78488372093\n",
      "House, val, indicator=female, SVM: 0.78488372093\n",
      "House, val, indicator=female, KNN: 0.854651162791\n",
      "House, val, indicator=female, DTC: 0.755813953488\n",
      "\n",
      "\n",
      "House, val, indicator=female_dem, LR: 0.843023255814\n",
      "House, val, indicator=female_dem, SVM: 0.837209302326\n",
      "House, val, indicator=female_dem, KNN: 0.895348837209\n",
      "House, val, indicator=female_dem, DTC: 0.813953488372\n",
      "\n",
      "\n",
      "House, test, indicator=female, LR: 0.734939759036\n",
      "House, test, indicator=female, SVM: 0.765060240964\n",
      "House, test, indicator=female, KNN: 0.765060240964\n",
      "House, test, indicator=female, DTC: 0.234939759036\n",
      "\n",
      "\n",
      "House, test, indicator=female_dem, LR: 0.78313253012\n",
      "House, test, indicator=female_dem, SVM: 0.825301204819\n",
      "House, test, indicator=female_dem, KNN: 0.825301204819\n",
      "House, test, indicator=female_dem, DTC: 0.475903614458\n"
     ]
    }
   ],
   "source": [
    "# House accuracies\n",
    "\n",
    "print('House, val, indicator=female, LR: ' + str(house_val_lr_female_accuracy))\n",
    "print('House, val, indicator=female, SVM: ' + str(house_val_svm_female_accuracy))\n",
    "print('House, val, indicator=female, KNN: ' + str(house_val_knn_female_accuracy))\n",
    "print('House, val, indicator=female, DTC: ' + str(house_val_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('House, val, indicator=female_dem, LR: ' + str(house_val_lr_femaleDem_accuracy))\n",
    "print('House, val, indicator=female_dem, SVM: ' + str(house_val_svm_femaleDem_accuracy))\n",
    "print('House, val, indicator=female_dem, KNN: ' + str(house_val_knn_femaleDem_accuracy))\n",
    "print('House, val, indicator=female_dem, DTC: ' + str(house_val_dtc_femaleDem_accuracy))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('House, test, indicator=female, LR: ' + str(house_test_lr_female_accuracy))\n",
    "print('House, test, indicator=female, SVM: ' + str(house_test_svm_female_accuracy))\n",
    "print('House, test, indicator=female, KNN: ' + str(house_test_knn_female_accuracy))\n",
    "print('House, test, indicator=female, DTC: ' + str(house_test_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('House, test, indicator=female_dem, LR: ' + str(house_test_lr_femaleDem_accuracy))\n",
    "print('House, test, indicator=female_dem, SVM: ' + str(house_test_svm_femaleDem_accuracy))\n",
    "print('House, test, indicator=female_dem, KNN: ' + str(house_test_knn_femaleDem_accuracy))\n",
    "print('House, test, indicator=female_dem, DTC: ' + str(house_test_dtc_femaleDem_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged, val, indicator=female, LR: 0.759842519685\n",
      "Merged, val, indicator=female, SVM: 0.763779527559\n",
      "Merged, val, indicator=female, KNN: 0.854330708661\n",
      "Merged, val, indicator=female, DTC: 0.692913385827\n",
      "\n",
      "\n",
      "Merged, val, indicator=female_dem, LR: 0.665354330709\n",
      "Merged, val, indicator=female_dem, SVM: 0.688976377953\n",
      "Merged, val, indicator=female_dem, KNN: 0.775590551181\n",
      "Merged, val, indicator=female_dem, DTC: 0.629921259843\n",
      "\n",
      "\n",
      "Merged, test, indicator=female, LR: 0.749003984064\n",
      "Merged, test, indicator=female, SVM: 0.749003984064\n",
      "Merged, test, indicator=female, KNN: 0.573705179283\n",
      "Merged, test, indicator=female, DTC: 0.745019920319\n",
      "\n",
      "\n",
      "Merged, test, indicator=female_dem, LR: 0.649402390438\n",
      "Merged, test, indicator=female_dem, SVM: 0.649402390438\n",
      "Merged, test, indicator=female_dem, KNN: 0.414342629482\n",
      "Merged, test, indicator=female_dem, DTC: 0.350597609562\n"
     ]
    }
   ],
   "source": [
    "# Merged accuracies\n",
    "\n",
    "print('Merged, val, indicator=female, LR: ' + str(merged_val_lr_female_accuracy))\n",
    "print('Merged, val, indicator=female, SVM: ' + str(merged_val_svm_female_accuracy))\n",
    "print('Merged, val, indicator=female, KNN: ' + str(merged_val_knn_female_accuracy))\n",
    "print('Merged, val, indicator=female, DTC: ' + str(merged_val_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('Merged, val, indicator=female_dem, LR: ' + str(merged_val_lr_femaleDem_accuracy))\n",
    "print('Merged, val, indicator=female_dem, SVM: ' + str(merged_val_svm_femaleDem_accuracy))\n",
    "print('Merged, val, indicator=female_dem, KNN: ' + str(merged_val_knn_femaleDem_accuracy))\n",
    "print('Merged, val, indicator=female_dem, DTC: ' + str(merged_val_dtc_femaleDem_accuracy))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Merged, test, indicator=female, LR: ' + str(merged_test_lr_female_accuracy))\n",
    "print('Merged, test, indicator=female, SVM: ' + str(merged_test_svm_female_accuracy))\n",
    "print('Merged, test, indicator=female, KNN: ' + str(merged_test_knn_female_accuracy))\n",
    "print('Merged, test, indicator=female, DTC: ' + str(merged_test_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('Merged, test, indicator=female_dem, LR: ' + str(merged_test_lr_femaleDem_accuracy))\n",
    "print('Merged, test, indicator=female_dem, SVM: ' + str(merged_test_svm_femaleDem_accuracy))\n",
    "print('Merged, test, indicator=female_dem, KNN: ' + str(merged_test_knn_femaleDem_accuracy))\n",
    "print('Merged, test, indicator=female_dem, DTC: ' + str(merged_test_dtc_femaleDem_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged, test on senate, indicator=female, LR: 0.717647058824\n",
      "Merged, test on senate, indicator=female, SVM: 0.717647058824\n",
      "Merged, test on senate, indicator=female, KNN: 0.623529411765\n",
      "Merged, test on senate, indicator=female, DTC: 0.717647058824\n",
      "\n",
      "\n",
      "Merged, test on senate, indicator=female_dem, LR: 0.717647058824\n",
      "Merged, test on senate, indicator=female_dem, SVM: 0.717647058824\n",
      "Merged, test on senate, indicator=female_dem, KNN: 0.388235294118\n",
      "Merged, test on senate, indicator=female_dem, DTC: 0.282352941176\n"
     ]
    }
   ],
   "source": [
    "print('Merged, test on senate, indicator=female, LR: ' + str(merged_test_senate_lr_female_accuracy))\n",
    "print('Merged, test on senate, indicator=female, SVM: ' + str(merged_test_senate_svm_female_accuracy))\n",
    "print('Merged, test on senate, indicator=female, KNN: ' + str(merged_test_senate_knn_female_accuracy))\n",
    "print('Merged, test on senate, indicator=female, DTC: ' + str(merged_test_senate_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('Merged, test on senate, indicator=female_dem, LR: ' + str(merged_test_senate_lr_femaleDem_accuracy))\n",
    "print('Merged, test on senate, indicator=female_dem, SVM: ' + str(merged_test_senate_svm_femaleDem_accuracy))\n",
    "print('Merged, test on senate, indicator=female_dem, KNN: ' + str(merged_test_senate_knn_femaleDem_accuracy))\n",
    "print('Merged, test on senate, indicator=female_dem, DTC: ' + str(merged_test_senate_dtc_femaleDem_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged, test on house, indicator=female, LR: 0.765060240964\n",
      "Merged, test on house, indicator=female, SVM: 0.765060240964\n",
      "Merged, test on house, indicator=female, KNN: 0.55421686747\n",
      "Merged, test on house, indicator=female, DTC: 0.759036144578\n",
      "\n",
      "\n",
      "Merged, test on house, indicator=female_dem, LR: 0.825301204819\n",
      "Merged, test on house, indicator=female_dem, SVM: 0.825301204819\n",
      "Merged, test on house, indicator=female_dem, KNN: 0.39156626506\n",
      "Merged, test on house, indicator=female_dem, DTC: 0.174698795181\n"
     ]
    }
   ],
   "source": [
    "print('Merged, test on house, indicator=female, LR: ' + str(merged_test_house_lr_female_accuracy))\n",
    "print('Merged, test on house, indicator=female, SVM: ' + str(merged_test_house_svm_female_accuracy))\n",
    "print('Merged, test on house, indicator=female, KNN: ' + str(merged_test_house_knn_female_accuracy))\n",
    "print('Merged, test on house, indicator=female, DTC: ' + str(merged_test_house_dtc_female_accuracy))\n",
    "print('\\n')\n",
    "print('Merged, test on house, indicator=female_dem, LR: ' + str(merged_test_house_lr_femaleDem_accuracy))\n",
    "print('Merged, test on house, indicator=female_dem, SVM: ' + str(merged_test_house_svm_femaleDem_accuracy))\n",
    "print('Merged, test on house, indicator=female_dem, KNN: ' + str(merged_test_house_knn_femaleDem_accuracy))\n",
    "print('Merged, test on house, indicator=female_dem, DTC: ' + str(merged_test_house_dtc_femaleDem_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "85\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 85 is out of bounds for axis 0 with size 85",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-492-63bdfd3f9583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0msen_pred_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msen_pred_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'District'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Probability_Female'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Probability_Female_Dem'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msen_pred_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0msen_pred_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Probability_Female'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_test_senate_lr_female_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0msen_pred_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Probability_Female_Dem'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_test_senate_lr_femaleDem_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 85 is out of bounds for axis 0 with size 85"
     ]
    }
   ],
   "source": [
    "senate_district_num_dict = {}\n",
    "house_district_num_dict = {}\n",
    "district_num_dict = {}\n",
    "\n",
    "for key, value in senate_name_dict.items():\n",
    "    senate_district_num_dict[value] = key\n",
    "\n",
    "for key, value in senate_name_dict.items():\n",
    "    senate_district_num_dict[value] = key\n",
    "\n",
    "for key, value in name_dict.items():\n",
    "    district_num_dict[value] = key\n",
    "    \n",
    "\n",
    "sen_pred_df = cleaned_train_senate.copy()\n",
    "print(len(sen_pred_df))\n",
    "print(len(merged_test_senate_lr_female_preds))\n",
    "\n",
    "sen_pred_df['Probability_Female'] = 0 \n",
    "sen_pred_df['Probability_Female_Dem'] = 0 \n",
    "sen_pred_df = sen_pred_df[['District','Probability_Female', 'Probability_Female_Dem']]\n",
    "for i, row in sen_pred_df.iterrows():\n",
    "    sen_pred_df.set_value(i, 'Probability_Female', merged_test_senate_lr_female_preds[i])\n",
    "    sen_pred_df.set_value(i, 'Probability_Female_Dem', merged_test_senate_lr_femaleDem_preds[i])\n",
    "\n",
    "print(sen_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
